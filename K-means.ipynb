{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df['species']\n",
    "df.drop(['species'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a numpy array\n",
    "\n",
    "data = df.values.tolist()\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting into Train and Test sets\n",
    "length = len(data)\n",
    "train_data = data[:int(length*0.8)]\n",
    "test_data = data[int(length*0.8):]\n",
    "\n",
    "len(train_data),len(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Centroids\n",
    "\n",
    "Note: We have selected the number of centroids as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3 7.9\n",
      "2.0 4.4\n",
      "1.0 6.9\n",
      "0.1 2.5\n"
     ]
    }
   ],
   "source": [
    "# First, we need to find the min and max values of each feature\n",
    "\n",
    "print(min(df['sepal_length']),max(df['sepal_length']))\n",
    "print(min(df['sepal_width']),max(df['sepal_width']))\n",
    "print(min(df['petal_length']),max(df['petal_length']))\n",
    "print(min(df['petal_width']),max(df['petal_width']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Centroids\n",
    "c1 = [float(random.randint(4,8)),float(random.randint(2,5)),float(random.randint(1,7)),float(random.randint(0,3))]\n",
    "c2 = [float(random.randint(4,8)),float(random.randint(2,5)),float(random.randint(1,7)),float(random.randint(0,3))]\n",
    "c3 = [float(random.randint(4,8)),float(random.randint(2,5)),float(random.randint(1,7)),float(random.randint(0,3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "while epochs <= 100:\n",
    "\n",
    "    cluster_1 = []\n",
    "    cluster_2 = []\n",
    "    cluster_3 = []\n",
    "    \n",
    "    for point in train_data:\n",
    "        \n",
    "        # Calculating the Ecludiean Distance\n",
    "        distance_to_c1 = ((c1[0]-point[0])**2 + (c1[1] - point[1])**2 + (c1[2]-point[2])**2 + (c1[3]-point[3])**2)**0.5\n",
    "        distance_to_c2 = ((c2[0]-point[0])**2 + (c2[1] - point[1])**2 + (c2[2]-point[2])**2 + (c2[3]-point[3])**2)**0.5\n",
    "        distance_to_c3 = ((c3[0]-point[0])**2 + (c3[1] - point[1])**2 + (c3[2]-point[2])**2 + (c3[3]-point[3])**2)**0.5\n",
    "\n",
    "\n",
    "        distances = [distance_to_c1,distance_to_c2,distance_to_c3]\n",
    "\n",
    "        minDistance = np.argmin(distances)\n",
    "\n",
    "        if minDistance == 0:\n",
    "            cluster_1.append(point)\n",
    "\n",
    "        elif minDistance == 1:\n",
    "            cluster_2.append(point)\n",
    "\n",
    "        else:\n",
    "            cluster_3.append(point)\n",
    "\n",
    "    # Saving the previous centroids\n",
    "    prev_c1 = c1\n",
    "    prev_c2 = c2\n",
    "    prev_c3 = c3\n",
    "\n",
    "    # Converting clusters to numpy array\n",
    "    cluster_1 = np.array(cluster_1)\n",
    "    cluster_2 = np.array(cluster_2)\n",
    "    cluster_3 = np.array(cluster_3)\n",
    "\n",
    "    # Finding new Centroids\n",
    "    if len(cluster_1) != 0:\n",
    "        c1 = [sum(cluster_1[:,0])/float(len(cluster_1)),sum(cluster_1[:,1])/float(len(cluster_1)),\n",
    "              sum(cluster_1[:,2])/float(len(cluster_1)),sum(cluster_1[:,3])/float(len(cluster_1))]\n",
    "\n",
    "    if len(cluster_2) != 0:\n",
    "        c2 = [sum(cluster_2[:,0])/float(len(cluster_2)),sum(cluster_2[:,1])/float(len(cluster_2)),\n",
    "              sum(cluster_2[:,2])/float(len(cluster_2)),sum(cluster_2[:,3])/float(len(cluster_2))]\n",
    "\n",
    "    if len(cluster_3) != 0:   \n",
    "        c3 = [sum(cluster_3[:,0])/float(len(cluster_3)),sum(cluster_3[:,1])/float(len(cluster_3)),\n",
    "              sum(cluster_3[:,2])/float(len(cluster_3)),sum(cluster_3[:,3])/float(len(cluster_3))]\n",
    "    \n",
    "\n",
    "    # Break if Centroids hasn't changed\n",
    "    if (c1 == prev_c1 and c2 == prev_c2 and c3 == prev_c3):\n",
    "        print('Converged')\n",
    "        break\n",
    "\n",
    "    print(epochs)\n",
    "    epochs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
